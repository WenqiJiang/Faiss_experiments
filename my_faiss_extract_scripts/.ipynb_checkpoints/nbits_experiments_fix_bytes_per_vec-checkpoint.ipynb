{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal:\n",
    "    In principle, we can construct the same bytes per vector by m and nbits. For example, 16 bytes per vector = 16 x 8 bits = 32 x 4 bits = 8 x 16 bits. Each of them have different tradeoffs:\n",
    "        1. the larger the nbits === the smaller the m: \n",
    "            (a) (-) the more effort is required to construct distance LUTs, as the computation cost is O(d * 2^nbits); \n",
    "            (b) (-) the more likely cache miss will happen (distance LUT has d * 2 ^ nbits elements) \n",
    "            (c) (+) the less operations per ADC due (but large tables can result in cache misses)\n",
    "            this setting should be better when there are many PQ codes in the table\n",
    "        2. it is unclear what combination of (m, nbits) can yield the best QPS / recall\n",
    "        \n",
    "On CPU, though, nbits=8 is probably the only option one want to use, because setting nbits=4 can reduce the performance by almost 10x, and setting nbits=16 will lead to a unnecessarily large distance LUT that results in unacceptable performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 128\n",
    "nb = int(1e6)\n",
    "nq = int(1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmap_bvecs(fname):\n",
    "    x = np.memmap(fname, dtype='uint8', mode='r')\n",
    "    d = x[:4].view('int32')[0]\n",
    "    return x.reshape(-1, d + 4)[:, 4:]\n",
    "\n",
    "def ivecs_read(fname):\n",
    "    a = np.fromfile(fname, dtype='int32')\n",
    "    d = a[0]\n",
    "    # Wenqi: Format of ground truth (for 10000 query vectors):\n",
    "    #   1000(topK), [1000 ids]\n",
    "    #   1000(topK), [1000 ids]\n",
    "    #        ...     ...\n",
    "    #   1000(topK), [1000 ids]\n",
    "    # 10000 rows in total, 10000 * 1001 elements, 10000 * 1001 * 4 bytes\n",
    "    return a.reshape(-1, d + 1)[:, 1:].copy()\n",
    "\n",
    "xb = mmap_bvecs('../bigann/bigann_base.bvecs')\n",
    "# trim xb to correct size\n",
    "xb = np.array(xb[:nb], dtype=np.float32)\n",
    "\n",
    "xq = mmap_bvecs('../bigann/bigann_query.bvecs')\n",
    "xq = np.array(xq[:nq], dtype=np.float32)\n",
    "\n",
    "# use the same learning set (always use the first 1e6 vectors)\n",
    "xt = mmap_bvecs('../bigann/bigann_learn.bvecs')\n",
    "xt = np.array(xt[:int(1e6)], dtype=np.float32)\n",
    "\n",
    "gt = ivecs_read('../bigann/gnd/idx_1M.ivecs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16 bytes per vector = m (16) * nbits (8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 16\n",
    "nbits = 8\n",
    "\n",
    "index_m_16_nbits_8 = faiss.IndexPQ(d, m, nbits) # 8 specifies that each sub-vector is encoded as 8 bits\n",
    "index_m_16_nbits_8.train(xt)\n",
    "index_m_16_nbits_8.add(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapse for searching 10000 queries: 16.39036202430725 sec\t throughput=610.1146506202724\n"
     ]
    }
   ],
   "source": [
    "# QPS evaluation\n",
    "k = 1\n",
    "\n",
    "start = time.time()\n",
    "D, I = index_m_16_nbits_8.search(xq, k) # sanity check\n",
    "end = time.time()\n",
    "print(\"Time elapse for searching {} queries: {} sec\\t throughput={}\".format(\n",
    "    nq, end - start, nq / (end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.4542\n"
     ]
    }
   ],
   "source": [
    "# recall evaluation\n",
    "n_ok = (I[:, :k] == gt[:, :1]).sum()\n",
    "recall = n_ok / float(nq)\n",
    "print(\"Recall: \", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16 bytes per vector = m (32) * nbits (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 32\n",
    "nbits = 4\n",
    "\n",
    "index_m_32_nbits_4 = faiss.IndexPQ(d, m, nbits) # 8 specifies that each sub-vector is encoded as 8 bits\n",
    "index_m_32_nbits_4.train(xt)\n",
    "index_m_32_nbits_4.add(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapse for searching 10000 queries: 126.39668345451355 sec\t throughput=79.1159999352254\n"
     ]
    }
   ],
   "source": [
    "# QPS evaluation\n",
    "k = 1\n",
    "\n",
    "start = time.time()\n",
    "D, I = index_m_32_nbits_4.search(xq, k) # sanity check\n",
    "end = time.time()\n",
    "print(\"Time elapse for searching {} queries: {} sec\\t throughput={}\".format(\n",
    "    nq, end - start, nq / (end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.3275\n"
     ]
    }
   ],
   "source": [
    "# recall evaluation\n",
    "n_ok = (I[:, :k] == gt[:, :1]).sum()\n",
    "recall = n_ok / float(nq)\n",
    "print(\"Recall: \", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16 bytes per vector = m (8) * nbits (16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 8\n",
    "nbits = 16\n",
    "\n",
    "index_m_8_nbits_16 = faiss.IndexPQ(d, m, nbits) # 8 specifies that each sub-vector is encoded as 8 bits\n",
    "index_m_8_nbits_16.train(xt)\n",
    "index_m_8_nbits_16.add(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QPS evaluation\n",
    "k = 1\n",
    "\n",
    "start = time.time()\n",
    "D, I = index_m_8_nbits_16.search(xq, k) # sanity check\n",
    "end = time.time()\n",
    "print(\"Time elapse for searching {} queries: {} sec\\t throughput={}\".format(\n",
    "    nq, end - start, nq / (end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall evaluation\n",
    "n_ok = (I[:, :k] == gt[:, :1]).sum()\n",
    "recall = n_ok / float(nq)\n",
    "print(\"Recall: \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
